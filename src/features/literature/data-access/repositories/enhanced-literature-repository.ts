/**
 * ğŸ—ï¸ Enhanced Literature Repository - ä¼˜åŒ–ç‰ˆæ–‡çŒ®ä»“å‚¨
 * 
 * è®¾è®¡åŸåˆ™:
 * 1. æ™ºèƒ½æŸ¥é‡ - åŸºäºå¤šå­—æ®µçš„ç›¸ä¼¼æ€§æ£€æµ‹
 * 2. é«˜æ€§èƒ½æŸ¥è¯¢ - åˆ©ç”¨ç´¢å¼•å’Œç¼“å­˜ä¼˜åŒ–
 * 3. æ‰¹é‡æ“ä½œ - æ”¯æŒå¤§é‡æ•°æ®çš„é«˜æ•ˆå¤„ç†
 * 4. äº‹åŠ¡æ”¯æŒ - å¤æ‚æ“ä½œçš„åŸå­æ€§ä¿è¯
 * 5. ç»Ÿä¸€é”™è¯¯å¤„ç† - é›†æˆé¢†åŸŸé”™è¯¯ç³»ç»Ÿ
 */

import { BaseRepository } from './base-repository';
import { enhancedLiteratureDB, type DatabaseStatistics } from '../database';
import {
    LibraryItemCore,
    CreateLiteratureInput,
    UpdateLiteratureInput,
    LiteratureFilter,
    LiteratureSort,
    PaginatedResult,
    ModelFactory,
    ModelValidators,
    ErrorHandler,
    NotFoundError,
    BusinessLogicError,
    withErrorBoundary,
    LITERATURE_CONSTANTS,
} from '../models';

/**
 * ğŸ¯ æ–‡çŒ®æ“ä½œç»“æœæ¥å£
 */
export interface LiteratureOperationResult {
    id: string;
    isNew: boolean;
    operation: 'created' | 'updated' | 'merged';
    mergedFields?: string[];
    duplicateScore?: number;
    message: string;
}

/**
 * ğŸ¯ æ‰¹é‡æ“ä½œç»“æœæ¥å£
 */
export interface BulkLiteratureResult {
    total: number;
    successful: number;
    failed: number;
    duplicates: number;
    results: LiteratureOperationResult[];
    executionTime: number;
    errors: Array<{ index: number; error: string; data?: any }>;
}

/**
 * ğŸ¯ ç›¸ä¼¼æ€§æ£€æµ‹ç»“æœæ¥å£
 */
export interface SimilarityResult {
    item: LibraryItemCore;
    score: number;
    matchedFields: string[];
    confidence: 'high' | 'medium' | 'low';
}

/**
 * ğŸ¯ æ–‡çŒ®ç»Ÿè®¡æ¥å£
 */
export interface LiteratureStatistics {
    total: number;
    bySource: Record<string, number>;
    byYear: Record<number, number>;
    byLanguage: Record<string, number>;
    byStatus: Record<string, number>;
    recentlyAdded: {
        lastDay: number;
        lastWeek: number;
        lastMonth: number;
    };
    topAuthors: Array<{ name: string; count: number }>;
    topKeywords: Array<{ keyword: string; count: number }>;
}

/**
 * ğŸ—ï¸ å¢å¼ºç‰ˆæ–‡çŒ®ä»“å‚¨ç±»
 */
export class EnhancedLiteratureRepository extends BaseRepository<LibraryItemCore, string> {
    protected table = enhancedLiteratureDB.libraries;
    protected generateId = () => crypto.randomUUID();

    // ğŸ“Š ç›¸ä¼¼æ€§æ£€æµ‹é˜ˆå€¼
    private readonly SIMILARITY_THRESHOLDS = {
        HIGH: 0.9,      // é«˜åº¦ç›¸ä¼¼ï¼Œå‡ ä¹ç¡®å®šæ˜¯é‡å¤
        MEDIUM: 0.7,    // ä¸­åº¦ç›¸ä¼¼ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
        LOW: 0.5,       // ä½åº¦ç›¸ä¼¼ï¼Œä»…ä½œä¸ºå‚è€ƒ
    };

    // ==================== æ ¸å¿ƒCRUDæ“ä½œå¢å¼º ====================

    /**
     * ğŸ” æ ¹æ®æ–‡çŒ®IDæŸ¥æ‰¾ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
     */
    @withErrorBoundary('findByLid', 'repository')
    async findByLid(lid: string): Promise<LibraryItemCore | null> {
        if (!lid) {
            throw new NotFoundError('LibraryItem', lid, {
                operation: 'findByLid',
                layer: 'repository',
            });
        }

        try {
            const item = await this.table.get(lid);
            return item || null;
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.findByLid',
                layer: 'repository',
                entityType: 'LibraryItem',
                entityId: lid,
            });
        }
    }

    /**
     * â• æ™ºèƒ½åˆ›å»ºæˆ–æ›´æ–°æ–‡çŒ®
     */
    @withErrorBoundary('createOrUpdate', 'repository')
    async createOrUpdate(input: CreateLiteratureInput): Promise<LiteratureOperationResult> {
        try {
            // 1. æ•°æ®éªŒè¯
            ModelValidators.createInput(input);

            // 2. æ™ºèƒ½æŸ¥é‡æ£€æµ‹
            const duplicateResults = await this.findSimilar(input);
            const highSimilarity = duplicateResults.find(r => r.score >= this.SIMILARITY_THRESHOLDS.HIGH);

            if (highSimilarity) {
                // é«˜åº¦ç›¸ä¼¼ï¼Œæ‰§è¡Œæ™ºèƒ½åˆå¹¶
                return await this.intelligentMerge(highSimilarity.item, input);
            }

            const mediumSimilarity = duplicateResults.find(r =>
                r.score >= this.SIMILARITY_THRESHOLDS.MEDIUM && r.score < this.SIMILARITY_THRESHOLDS.HIGH
            );

            if (mediumSimilarity) {
                // ä¸­åº¦ç›¸ä¼¼ï¼Œæç¤ºç”¨æˆ·ä½†ä»åˆ›å»ºæ–°è®°å½•
                const newItem = ModelFactory.createLiteratureItem(input);
                await this.table.add(newItem);

                return {
                    id: newItem.lid,
                    isNew: true,
                    operation: 'created',
                    duplicateScore: mediumSimilarity.score,
                    message: `Created new literature item (potential duplicate detected with score ${mediumSimilarity.score.toFixed(2)})`,
                };
            }

            // 3. åˆ›å»ºæ–°æ–‡çŒ®
            const newItem = ModelFactory.createLiteratureItem(input);
            await this.table.add(newItem);

            return {
                id: newItem.lid,
                isNew: true,
                operation: 'created',
                message: 'Literature item created successfully',
            };
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.createOrUpdate',
                layer: 'repository',
                inputData: input,
            });
        }
    }

    /**
     * ğŸ“¦ æ‰¹é‡å¯¼å…¥æ–‡çŒ®
     */
    @withErrorBoundary('bulkImport', 'repository')
    async bulkImport(inputs: CreateLiteratureInput[]): Promise<BulkLiteratureResult> {
        const startTime = Date.now();
        const results: LiteratureOperationResult[] = [];
        const errors: Array<{ index: number; error: string; data?: any }> = [];

        let successful = 0;
        let failed = 0;
        let duplicates = 0;

        try {
            // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜å‹åŠ›
            const batchSize = Math.min(LITERATURE_CONSTANTS.MAX_BULK_SIZE, 100);

            for (let i = 0; i < inputs.length; i += batchSize) {
                const batch = inputs.slice(i, i + batchSize);

                // ä½¿ç”¨äº‹åŠ¡å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
                await enhancedLiteratureDB.transaction('rw', this.table, async (tx) => {
                    for (let j = 0; j < batch.length; j++) {
                        const input = batch[j];
                        const globalIndex = i + j;

                        try {
                            const result = await this.createOrUpdate(input);
                            results.push(result);

                            if (result.isNew) {
                                successful++;
                            } else {
                                duplicates++;
                            }
                        } catch (error) {
                            failed++;
                            errors.push({
                                index: globalIndex,
                                error: error instanceof Error ? error.message : String(error),
                                data: input,
                            });
                        }
                    }
                });
            }

            return {
                total: inputs.length,
                successful,
                failed,
                duplicates,
                results,
                executionTime: Date.now() - startTime,
                errors,
            };
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.bulkImport',
                layer: 'repository',
                additionalInfo: { totalInputs: inputs.length },
            });
        }
    }

    // ==================== é«˜çº§æŸ¥è¯¢åŠŸèƒ½ ====================

    /**
     * ğŸ” é«˜çº§æœç´¢æ–‡çŒ®
     */
    @withErrorBoundary('searchWithFilters', 'repository')
    async searchWithFilters(
        filter: LiteratureFilter = {},
        sort: LiteratureSort = { field: 'createdAt', order: 'desc' },
        page: number = 1,
        pageSize: number = LITERATURE_CONSTANTS.DEFAULT_PAGE_SIZE
    ): Promise<PaginatedResult<LibraryItemCore>> {
        try {
            // ä½¿ç”¨å¢å¼ºç‰ˆæ•°æ®åº“çš„é«˜æ€§èƒ½æœç´¢
            return await enhancedLiteratureDB.searchLiteratures(filter, sort, page, pageSize);
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.searchWithFilters',
                layer: 'repository',
                additionalInfo: { filter, sort, page, pageSize },
            });
        }
    }

    /**
     * ğŸ” æ ¹æ®æ ‡é¢˜ç›¸ä¼¼æ€§æŸ¥æ‰¾æ–‡çŒ®
     */
    @withErrorBoundary('findByTitleSimilar', 'repository')
    async findByTitleSimilar(
        title: string,
        threshold: number = 0.6,
        limit: number = 10
    ): Promise<LibraryItemCore[]> {
        try {
            const allItems = await this.table.toArray();
            const similarItems: Array<{ item: LibraryItemCore; score: number }> = [];

            for (const item of allItems) {
                const score = this.calculateTitleSimilarity(title, item.title);
                if (score >= threshold) {
                    similarItems.push({ item, score });
                }
            }

            // æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶é™åˆ¶æ•°é‡
            return similarItems
                .sort((a, b) => b.score - a.score)
                .slice(0, limit)
                .map(result => result.item);
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.findByTitleSimilar',
                layer: 'repository',
                additionalInfo: { title, threshold, limit },
            });
        }
    }

    /**
     * ğŸ” æŸ¥æ‰¾ç›¸ä¼¼æ–‡çŒ®ï¼ˆç»¼åˆç›¸ä¼¼æ€§ï¼‰
     */
    @withErrorBoundary('findSimilar', 'repository')
    async findSimilar(
        input: CreateLiteratureInput | LibraryItemCore,
        limit: number = 10
    ): Promise<SimilarityResult[]> {
        try {
            const allItems = await this.table.toArray();
            const similarities: SimilarityResult[] = [];

            for (const item of allItems) {
                const similarity = this.calculateComprehensiveSimilarity(input, item);

                if (similarity.score >= this.SIMILARITY_THRESHOLDS.LOW) {
                    similarities.push(similarity);
                }
            }

            // æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶é™åˆ¶æ•°é‡
            return similarities
                .sort((a, b) => b.score - a.score)
                .slice(0, limit);
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.findSimilar',
                layer: 'repository',
                additionalInfo: { limit },
            });
        }
    }

    /**
     * ğŸ“Š è·å–æ–‡çŒ®ç»Ÿè®¡ä¿¡æ¯
     */
    @withErrorBoundary('getStatistics', 'repository')
    async getStatistics(): Promise<LiteratureStatistics> {
        try {
            const allItems = await this.table.toArray();
            const now = new Date();
            const oneDayAgo = new Date(now.getTime() - 24 * 60 * 60 * 1000);
            const oneWeekAgo = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);
            const oneMonthAgo = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);

            // åŸºæœ¬ç»Ÿè®¡
            const bySource: Record<string, number> = {};
            const byYear: Record<number, number> = {};
            const byLanguage: Record<string, number> = {};
            const byStatus: Record<string, number> = {};

            // ä½œè€…ç»Ÿè®¡
            const authorCounts: Record<string, number> = {};
            const keywordCounts: Record<string, number> = {};

            let recentDay = 0;
            let recentWeek = 0;
            let recentMonth = 0;

            for (const item of allItems) {
                // æ¥æºç»Ÿè®¡
                bySource[item.source] = (bySource[item.source] || 0) + 1;

                // å¹´ä»½ç»Ÿè®¡
                if (item.year) {
                    byYear[item.year] = (byYear[item.year] || 0) + 1;
                }

                // è¯­è¨€ç»Ÿè®¡
                byLanguage[item.language] = (byLanguage[item.language] || 0) + 1;

                // çŠ¶æ€ç»Ÿè®¡
                byStatus[item.status] = (byStatus[item.status] || 0) + 1;

                // ä½œè€…ç»Ÿè®¡
                for (const author of item.authors) {
                    authorCounts[author] = (authorCounts[author] || 0) + 1;
                }

                // å…³é”®è¯ç»Ÿè®¡
                for (const keyword of item.keywords) {
                    keywordCounts[keyword] = (keywordCounts[keyword] || 0) + 1;
                }

                // æ—¶é—´ç»Ÿè®¡
                if (item.createdAt > oneDayAgo) recentDay++;
                if (item.createdAt > oneWeekAgo) recentWeek++;
                if (item.createdAt > oneMonthAgo) recentMonth++;
            }

            // æ’åºè·å–Topé¡¹
            const topAuthors = Object.entries(authorCounts)
                .sort((a, b) => b[1] - a[1])
                .slice(0, 20)
                .map(([name, count]) => ({ name, count }));

            const topKeywords = Object.entries(keywordCounts)
                .sort((a, b) => b[1] - a[1])
                .slice(0, 30)
                .map(([keyword, count]) => ({ keyword, count }));

            return {
                total: allItems.length,
                bySource,
                byYear,
                byLanguage,
                byStatus,
                recentlyAdded: {
                    lastDay: recentDay,
                    lastWeek: recentWeek,
                    lastMonth: recentMonth,
                },
                topAuthors,
                topKeywords,
            };
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.getStatistics',
                layer: 'repository',
            });
        }
    }

    // ==================== ç»´æŠ¤æ“ä½œ ====================

    /**
     * ğŸ§¹ æ¸…ç†é‡å¤æ–‡çŒ®
     */
    @withErrorBoundary('cleanupDuplicates', 'repository')
    async cleanupDuplicates(): Promise<{
        duplicatesFound: number;
        duplicatesRemoved: number;
        mergedItems: number;
    }> {
        try {
            const allItems = await this.table.toArray();
            const duplicateGroups: LibraryItemCore[][] = [];
            const processedIds = new Set<string>();

            // æŸ¥æ‰¾é‡å¤ç»„
            for (const item of allItems) {
                if (processedIds.has(item.lid)) continue;

                const duplicates = [item];
                processedIds.add(item.lid);

                // æŸ¥æ‰¾ä¸å½“å‰é¡¹ç›®ç›¸ä¼¼çš„å…¶ä»–é¡¹ç›®
                for (const otherItem of allItems) {
                    if (processedIds.has(otherItem.lid)) continue;

                    const similarity = this.calculateComprehensiveSimilarity(item, otherItem);
                    if (similarity.score >= this.SIMILARITY_THRESHOLDS.HIGH) {
                        duplicates.push(otherItem);
                        processedIds.add(otherItem.lid);
                    }
                }

                if (duplicates.length > 1) {
                    duplicateGroups.push(duplicates);
                }
            }

            // å¤„ç†é‡å¤ç»„
            let duplicatesRemoved = 0;
            let mergedItems = 0;

            for (const group of duplicateGroups) {
                // é€‰æ‹©æœ€å®Œæ•´çš„è®°å½•ä½œä¸ºä¸»è®°å½•
                const primaryItem = this.selectPrimaryItem(group);
                const duplicateIds = group
                    .filter(item => item.lid !== primaryItem.lid)
                    .map(item => item.lid);

                // åˆ é™¤é‡å¤é¡¹
                await this.table.bulkDelete(duplicateIds);
                duplicatesRemoved += duplicateIds.length;
                mergedItems++;
            }

            return {
                duplicatesFound: duplicateGroups.reduce((sum, group) => sum + group.length - 1, 0),
                duplicatesRemoved,
                mergedItems,
            };
        } catch (error) {
            throw ErrorHandler.handle(error, {
                operation: 'repository.cleanupDuplicates',
                layer: 'repository',
            });
        }
    }

    // ==================== ç§æœ‰è¾…åŠ©æ–¹æ³• ====================

    /**
     * ğŸ” è®¡ç®—æ ‡é¢˜ç›¸ä¼¼åº¦
     */
    private calculateTitleSimilarity(title1: string, title2: string): number {
        const normalize = (str: string) => str.toLowerCase().trim().replace(/[^\w\s]/g, '');
        const t1 = normalize(title1);
        const t2 = normalize(title2);

        if (t1 === t2) return 1.0;

        // ä½¿ç”¨Jaccardç›¸ä¼¼åº¦
        const words1 = new Set(t1.split(/\s+/));
        const words2 = new Set(t2.split(/\s+/));

        const intersection = new Set([...words1].filter(word => words2.has(word)));
        const union = new Set([...words1, ...words2]);

        return intersection.size / union.size;
    }

    /**
     * ğŸ” è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦
     */
    private calculateComprehensiveSimilarity(
        item1: CreateLiteratureInput | LibraryItemCore,
        item2: LibraryItemCore
    ): SimilarityResult {
        const matchedFields: string[] = [];
        let totalScore = 0;
        let weightSum = 0;

        // æ ‡é¢˜ç›¸ä¼¼åº¦ (æƒé‡: 40%)
        const titleScore = this.calculateTitleSimilarity(item1.title, item2.title);
        if (titleScore > 0.3) {
            matchedFields.push('title');
            totalScore += titleScore * 0.4;
        }
        weightSum += 0.4;

        // ä½œè€…ç›¸ä¼¼åº¦ (æƒé‡: 25%)
        const authorScore = this.calculateAuthorSimilarity(item1.authors, item2.authors);
        if (authorScore > 0.3) {
            matchedFields.push('authors');
            totalScore += authorScore * 0.25;
        }
        weightSum += 0.25;

        // DOIåŒ¹é… (æƒé‡: 20%)
        if (item1.doi && item2.doi && item1.doi === item2.doi) {
            matchedFields.push('doi');
            totalScore += 1.0 * 0.2;
        }
        weightSum += 0.2;

        // å¹´ä»½åŒ¹é… (æƒé‡: 10%)
        if (item1.year && item2.year && item1.year === item2.year) {
            matchedFields.push('year');
            totalScore += 1.0 * 0.1;
        }
        weightSum += 0.1;

        // URLåŒ¹é… (æƒé‡: 5%)
        if (item1.url && item2.url && item1.url === item2.url) {
            matchedFields.push('url');
            totalScore += 1.0 * 0.05;
        }
        weightSum += 0.05;

        const finalScore = weightSum > 0 ? totalScore / weightSum : 0;

        let confidence: 'high' | 'medium' | 'low';
        if (finalScore >= this.SIMILARITY_THRESHOLDS.HIGH) {
            confidence = 'high';
        } else if (finalScore >= this.SIMILARITY_THRESHOLDS.MEDIUM) {
            confidence = 'medium';
        } else {
            confidence = 'low';
        }

        return {
            item: item2,
            score: finalScore,
            matchedFields,
            confidence,
        };
    }

    /**
     * ğŸ” è®¡ç®—ä½œè€…ç›¸ä¼¼åº¦
     */
    private calculateAuthorSimilarity(authors1: string[], authors2: string[]): number {
        if (authors1.length === 0 && authors2.length === 0) return 1.0;
        if (authors1.length === 0 || authors2.length === 0) return 0.0;

        const normalize = (authors: string[]) =>
            authors.map(author => author.toLowerCase().trim());

        const a1 = new Set(normalize(authors1));
        const a2 = new Set(normalize(authors2));

        const intersection = new Set([...a1].filter(author => a2.has(author)));
        const union = new Set([...a1, ...a2]);

        return intersection.size / union.size;
    }

    /**
     * ğŸ¤– æ™ºèƒ½åˆå¹¶æ–‡çŒ®è®°å½•
     */
    private async intelligentMerge(
        existingItem: LibraryItemCore,
        newInput: CreateLiteratureInput
    ): Promise<LiteratureOperationResult> {
        const mergedFields: string[] = [];
        const updates: Partial<LibraryItemCore> = {};

        // æ™ºèƒ½åˆå¹¶é€»è¾‘
        if (!existingItem.abstract && newInput.abstract) {
            updates.abstract = newInput.abstract;
            mergedFields.push('abstract');
        }

        if (!existingItem.doi && newInput.doi) {
            updates.doi = newInput.doi;
            mergedFields.push('doi');
        }

        if (!existingItem.url && newInput.url) {
            updates.url = newInput.url;
            mergedFields.push('url');
        }

        if (!existingItem.pdfPath && newInput.pdfPath) {
            updates.pdfPath = newInput.pdfPath;
            mergedFields.push('pdfPath');
        }

        // åˆå¹¶å…³é”®è¯
        const newKeywords = newInput.keywords?.filter(
            keyword => !existingItem.keywords.includes(keyword)
        ) || [];

        if (newKeywords.length > 0) {
            updates.keywords = [...existingItem.keywords, ...newKeywords];
            mergedFields.push('keywords');
        }

        // å¦‚æœæœ‰æ›´æ–°ï¼Œæ‰§è¡Œåˆå¹¶
        if (Object.keys(updates).length > 0) {
            await this.update(existingItem.lid, updates);
        }

        return {
            id: existingItem.lid,
            isNew: false,
            operation: 'merged',
            mergedFields,
            message: `Merged ${mergedFields.length} fields into existing literature item`,
        };
    }

    /**
     * ğŸ¯ é€‰æ‹©ä¸»è¦è®°å½•ï¼ˆç”¨äºå»é‡ï¼‰
     */
    private selectPrimaryItem(items: LibraryItemCore[]): LibraryItemCore {
        // é€‰æ‹©æœ€å®Œæ•´çš„è®°å½•ä½œä¸ºä¸»è®°å½•
        return items.reduce((primary, current) => {
            const primaryScore = this.calculateCompletenessScore(primary);
            const currentScore = this.calculateCompletenessScore(current);

            return currentScore > primaryScore ? current : primary;
        });
    }

    /**
     * ğŸ“Š è®¡ç®—è®°å½•å®Œæ•´åº¦è¯„åˆ†
     */
    private calculateCompletenessScore(item: LibraryItemCore): number {
        let score = 0;

        if (item.title) score += 2;
        if (item.authors.length > 0) score += 2;
        if (item.abstract) score += 1;
        if (item.doi) score += 1;
        if (item.url) score += 1;
        if (item.year) score += 1;
        if (item.publication) score += 1;
        if (item.keywords.length > 0) score += 1;
        if (item.pdfPath) score += 1;

        return score;
    }
}

// ğŸª ä»“å‚¨å®ä¾‹
export const enhancedLiteratureRepository = new EnhancedLiteratureRepository();

export default enhancedLiteratureRepository;
